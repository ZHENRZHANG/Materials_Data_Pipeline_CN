"""
ğŸŒŸ è„šæœ¬åç§°ï¼šPOSCARæ•°æ®è§£æä¸MongoDBå…¥åº“å·¥å…·

ğŸ“Œ åŠŸèƒ½æ¦‚è¿°ï¼š
æœ¬è„šæœ¬ç”¨äºè‡ªåŠ¨åŒ–å¤„ç†ææ–™ç§‘å­¦ä¸­çš„ POSCAR/CONTCAR æ–‡ä»¶ï¼Œæå–æ™¶ä½“ç»“æ„ä¿¡æ¯ï¼ˆæ™¶æ ¼ã€åŸå­åæ ‡ã€åŒ–å­¦å¼ç­‰ï¼‰ï¼Œ
å¹¶ç»“åˆå¤–éƒ¨è¶…å¯¼ç›¸å…³å±æ€§æ•°æ®ï¼ˆå¦‚ Î»ã€Tcã€å½¢æˆèƒ½ç­‰ï¼‰ï¼Œå°†ç»“æ„åŒ–æ•°æ®æ‰¹é‡å¯¼å…¥ MongoDB æ•°æ®åº“ã€‚
åŒæ—¶æ”¯æŒå»é‡æ›´æ–°ã€æ–‡ä»¶å½’æ¡£ä¸é™„ä»¶ï¼ˆå›¾åƒã€æ•°æ®æ–‡ä»¶ï¼‰è‡ªåŠ¨å¤åˆ¶ï¼Œé€‚ç”¨äºé«˜é€šé‡è®¡ç®—æ•°æ®ç®¡ç†ã€‚

ğŸ”§ æ ¸å¿ƒåŠŸèƒ½ï¼š
1. âœ… è‡ªåŠ¨è§£ææ–‡ä»¶è·¯å¾„ä¸­çš„åŒ–å­¦å¼ï¼ˆæ”¯æŒå¤æ‚å‘½åè§„åˆ™ï¼‰
2. âœ… è¯»å– POSCAR/CONTCAR æ–‡ä»¶ï¼Œæ„å»ºæ ‡å‡†æ™¶ä½“ç»“æ„æ•°æ®ï¼ˆlattice + sitesï¼‰
3. âœ… å…³è”å¤–éƒ¨å±æ€§æ•°æ®ï¼ˆæ¥è‡ª 'åˆå¹¶åçš„æ•°æ®.txt'ï¼Œæ”¯æŒå¤šåˆ—æ ¼å¼ï¼‰
4. âœ… æ™ºèƒ½ç”Ÿæˆå”¯ä¸€ entry_idï¼ˆå¦‚ ID-1, ID-2...ï¼‰ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
5. âœ… åŸºäºç»“æ„å†…å®¹ï¼ˆlattice å’Œ sitesï¼‰åˆ¤æ–­æ˜¯å¦å·²å­˜åœ¨ï¼Œå®ç° upsertï¼ˆå­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™æ’å…¥ï¼‰
6. âœ… è‡ªåŠ¨åˆ›å»ºä»¥ entry_id å‘½åçš„æ–‡ä»¶å¤¹ï¼Œå½’æ¡£ç»“æ„æ–‡ä»¶ä¸ç›¸å…³å›¾è¡¨ï¼ˆgamma-figsum.png, omega.datï¼‰
7. âœ… æ”¯æŒä» config.json è¯»å–æ•°æ®åº“é…ç½®ï¼Œé¿å…ç¡¬ç¼–ç ï¼Œæå‡å®‰å…¨æ€§ä¸å¯ç§»æ¤æ€§

ğŸ“ è¾“å…¥è¦æ±‚ï¼š
- POSCAR/CONTCAR æ–‡ä»¶è·¯å¾„ç»“æ„ç¤ºä¾‹ï¼š
    D:/.../work/Fe2Se/CONTCAR
    ï¼ˆæ–‡ä»¶å¤¹ååº”åŒ…å«åŒ–å­¦å¼ï¼Œå¦‚ Fe2Seï¼‰
- å¤–éƒ¨å±æ€§æ•°æ®æ–‡ä»¶ï¼š
    "åˆå¹¶åçš„æ•°æ®.txt"ï¼Œä½äºæ¯ä¸ªå·¥ä½œç›®å½•ä¸‹ï¼Œæ ¼å¼ä¸º TSVï¼ˆåˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰ï¼Œæ”¯æŒä»¥ä¸‹åˆ—ï¼š
    åŒ–å­¦å¼    formation_e    E_d    lambda    img_nu    low_three
    æˆ–
    åŒ–å­¦å¼    formation_e    E_d


ğŸ“¦ è¾“å‡ºç»“æœï¼š
- æ•°æ®å†™å…¥ MongoDB æŒ‡å®šé›†åˆ
- æ¯ä¸ªææ–™ç”Ÿæˆç‹¬ç«‹æ–‡ä»¶å¤¹ï¼ˆå¦‚ ID-100/ï¼‰ï¼ŒåŒ…å«ï¼š
    - {åŒ–å­¦å¼}.vaspï¼ˆç»“æ„æ–‡ä»¶å‰¯æœ¬ï¼‰
    - gamma-figsum.pngï¼ˆè¶…å¯¼è°±å›¾ï¼‰
    - omega.datï¼ˆå£°å­é¢‘ç‡æ•°æ®ï¼‰

â— æ³¨æ„äº‹é¡¹ï¼š
- è‹¥åŒ–å­¦å¼æ— æ³•ä»è·¯å¾„ä¸­è§£æï¼Œä¼šè®°å½•åˆ° '012-poscar2mondodb_wrong' å¹¶è·³è¿‡
- è‹¥æ•°æ®åº“ä¸­å·²å­˜åœ¨ç›¸åŒç»“æ„ï¼Œå°†ä¿ç•™åŸ entry_id å¹¶å¼ºåˆ¶æ›´æ–°å†…å®¹
- è¯·ç¡®ä¿ MongoDB å…·å¤‡è¯»å†™æƒé™ï¼Œå¹¶æå‰å¤‡ä»½é‡è¦æ•°æ®

ğŸš€ ä½¿ç”¨å»ºè®®ï¼š
1. ä¿®æ”¹ folder_paths ä¸ºä½ çš„å®é™…æ•°æ®ç›®å½•
2. ç¡®ä¿ 'åˆå¹¶åçš„æ•°æ®.txt' æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®
3. é¦–æ¬¡è¿è¡Œå»ºè®®å…ˆå¤‡ä»½æ•°æ®åº“
4. å¯é€šè¿‡æ³¨é‡Š start_count ç›¸å…³é€»è¾‘å¼ºåˆ¶ä» ID-1 å¼€å§‹

ğŸ“… ä½œè€…ï¼šå¼ åœ³é”
"""
from pymongo import MongoClient
import os
import shutil
import json
import ast
from datetime import datetime, timezone
import re
import json

# è¯»å–é…ç½®æ–‡ä»¶
with open("config.json", "r") as f:
    config = json.load(f)["mongodb"]

client = MongoClient(config["uri"])
collection = client[config["db_name"]][config["collection_name"]]



# ===============================================
def extract_formula_from_path(file_path):
    """
    ä»æ–‡ä»¶è·¯å¾„ä¸­æå–åŒ–å­¦å¼çš„é«˜çº§åŒ¹é…æ–¹æ³•

    å‚æ•°:
        file_path: æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²

    è¿”å›:
        æå–åˆ°çš„åŒ–å­¦å¼å­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
    """
    # æ”¹è¿›åçš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œå…è®¸å…ƒç´ åæ²¡æœ‰æ•°å­—
    pattern = r'([A-Z][a-z]?(?:\d*[A-Z][a-z]?\d*)*)'

    # ä»è·¯å¾„ä¸­æå–å¯èƒ½çš„åŒ–å­¦å¼éƒ¨åˆ†
    matches = re.findall(pattern, file_path)

    if matches:
        # ä¼˜å…ˆå–è¾ƒé•¿çš„åŒ¹é…ï¼ˆå‡è®¾åŒ–å­¦å¼ä¼šæ›´é•¿ï¼‰
        matches.sort(key=len, reverse=True)

        # éªŒè¯æ˜¯å¦æ˜¯åˆç†çš„åŒ–å­¦å¼
        for candidate in matches:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è‡³å°‘ä¸¤ä¸ªå…ƒç´ 
            elements = re.findall(r'([A-Z][a-z]?)', candidate)
            if len(elements) >= 2:
                # ç§»é™¤å¯¹æ•°å­—çš„å¼ºåˆ¶è¦æ±‚ï¼Œä½†ä»ä¿ç•™å¯¹æœ‰æ•ˆå…ƒç´ ç»„åˆçš„æ£€æŸ¥
                # æ£€æŸ¥æ˜¯å¦åªåŒ…å«å…ƒç´ ç¬¦å·å’Œæ•°å­—
                if re.fullmatch(r'([A-Z][a-z]?\d*)+', candidate):
                    return candidate

    return None


def parse_poscar_composition(path, current_count):
    with open(path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    # æ™¶æ ¼çŸ©é˜µ
    lattice_matrix = []
    for i in range(2, 5):
        lattice_matrix.append([float(x) for x in lines[i].split()])

    # ç¬¬6è¡Œä¸ºå…ƒç´ åè¡Œ
    elements = lines[5].split()
    counts = list(map(int, lines[6].split()))
    composition = dict(zip(elements, counts))

    # åŸå­åæ ‡
    sites = []
    index = 8

    # éå†æ¯ç§å…ƒç´ åŠå…¶å¯¹åº”çš„æ•°é‡
    for element, count in zip(elements, counts):
        for _ in range(count):
            coords = list(map(float, lines[index].split()))
            sites.append({
                "species": [{"element": element, "occu": 1}],
                "abc": coords,
                "label": element
            })
            index += 1  # æ›´æ–°ç´¢å¼•ä»¥æŒ‡å‘ä¸‹ä¸€ä¸ªåŸå­çš„ä½ç½®

    #  è¶…å¯¼ç›¸å…³
    #  è¿™é‡Œéœ€è¦ä½ ä¿®æ”¹
    #material_name = path.split("-")[-4]  ## éœ€è¦é«˜çº§é…ç¬¦
    material_name = extract_formula_from_path(path)

    if chem_dict.get(material_name):
        lambda_gamma = chem_dict.get(material_name, {}).get('lambda', None)
        energy_relative_to_convex_hull = chem_dict.get(material_name, {}).get('E_d (eV/atom)', None)
        img_number = chem_dict.get(material_name, {}).get('img_nu', None)
        formation_energy = chem_dict.get(material_name, {}).get('formation_e (eV/atom)', None)
        a = chem_dict.get(material_name, {}).get('low_three', None)

        if a is None:
            low_three = None
        else:
            # åªæœ‰ a ä¸æ˜¯ None æ—¶ï¼Œæ‰è¿›è¡Œå­—ç¬¦ä¸²æ“ä½œ
            cleaned_str = a.replace('\n', '').replace(' ', '')
            low_three = ast.literal_eval(cleaned_str)
        current_utc_time = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M%z")

        result = {
            "entry_id": f"ID-{current_count}",
            "composition": composition,
            "original-structure": "ThB5(P4/mmm)",
            "datatime": current_utc_time,
            "structure": {
                "lattice": {
                    "matrix": lattice_matrix,
                },
                "sites": sites,
                "Superconductivity_related_properties": {
                    "lambda_gamma": lambda_gamma if 'lambda_gamma' in locals() and lambda_gamma is not None else None,
                    "energy_above_hull": energy_relative_to_convex_hull if 'energy_relative_to_convex_hull' in locals() and energy_relative_to_convex_hull is not None else None,
                    "img_number": img_number if 'img_number' in locals() and img_number is not None else None,
                    "formation_energy": formation_energy if 'formation_energy' in locals() and formation_energy is not None else None,
                    "low_three": low_three if 'low_three' in locals() and low_three is not None else None
                }
            }
        }
        return result
    else:
        print(material_name + " è¯¥åŒ–å­¦å¼ä¸åœ¨å­—å…¸ä¸­")
        with open('012-poscar2mondodb_wrong.txt', 'a', encoding='utf-8') as f:
            f.write(path + '\n')
        return "error"


# è·å–å½“å‰æœ€å¤§çš„entry_idæ•°å€¼ï¼Œç”¨äºé€’å¢è®¡æ•°
def get_max_entry_id(collection):
    # æŒ‰æ•°å­—éƒ¨åˆ†é™åºæ’åºï¼Œå–ç¬¬ä¸€æ¡ï¼ˆä¿®æ­£æ’åºé€»è¾‘ï¼‰
    pipeline = [
        {
            "$addFields": {
                "entry_num": {
                    "$toInt": {
                        "$arrayElemAt": [{"$split": ["$entry_id", "-"]}, 1]
                    }
                }
            }
        },
        {"$sort": {"entry_num": -1}},
        {"$limit": 1}
    ]
    max_docs = list(collection.aggregate(pipeline))
    if not max_docs or "entry_id" not in max_docs[0]:
        return 0  # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œä»1å¼€å§‹
    # æå–æ•°å­—éƒ¨åˆ†ï¼ˆä¾‹å¦‚ä»"ID-5"ä¸­æå–5ï¼‰
    return int(max_docs[0]["entry_id"].split("-")[-1])


# è·å–èµ·å§‹è®¡æ•°
start_count = get_max_entry_id(collection) + 1  # ä¸‹ä¸€ä¸ªè¦åˆ†é…çš„ID
# start_count = 1  # å¦‚æœéœ€è¦ä»1å¼€å§‹è®¡æ•°ï¼Œå¯ä»¥å°†æ­¤è¡Œå–æ¶ˆæ³¨é‡Š
current_count = start_count  # å½“å‰è®¡æ•°

# å®šä¹‰æ–‡ä»¶å¤¹è·¯å¾„åˆ—è¡¨
folder_paths = [
    r"D:\School\SophomoreStudyMaterials\00MachineLearning\7.fuwuqi\work\work",
]
for folder_path in folder_paths:
    target_file_path = os.path.join(folder_path, 'åˆå¹¶åçš„æ•°æ®.txt')
    chem_dict = {}
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆå¯é€‰ï¼‰
    if os.path.exists(target_file_path):
        with open(target_file_path, 'r') as f1:
            lines = f1.readlines()
            # è·³è¿‡æ ‡é¢˜è¡Œï¼ˆå‡è®¾ç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜ï¼‰
            for line in lines[1:]:
                # å»é™¤è¡Œé¦–å°¾çš„ç©ºç™½å­—ç¬¦
                line = line.strip()
                # åˆ†å‰²è¡Œä¸­çš„æ•°æ®
                parts = [part.strip() for part in line.split('\t') if part.strip()]

                # ç¡®ä¿è¡Œä¸­æœ‰è¶³å¤Ÿçš„æ•°æ®
                if len(parts) >= 6:
                    chem, formation_e, e_d, lambda_val, img_nu, low_three = parts
                    # print(chem)
                    chem_dict[chem] = {
                        'lambda': float(lambda_val),
                        'E_d (eV/atom)': float(e_d),
                        'formation_e (eV/atom)': float(formation_e),
                        'img_nu': int(img_nu),
                        'low_three': low_three
                    }

                if len(parts) == 3:
                    chem, formation_e, e_d = parts
                    chem = chem.split('-')[1]  # æå–åŒ–å­¦å¼éƒ¨åˆ†
                    chem_dict[chem] = {
                        'formation_e (eV/atom)': float(formation_e),
                        'E_d (eV/atom)': float(e_d)
                    }
    print(folder_path)
    for file_path in os.listdir(folder_path):
        if "-" in file_path:
            # formula = file_path.split("-")[1]  # æå–åŒ–å­¦å¼

            formula = extract_formula_from_path(file_path)
            gamma_png = os.path.join(folder_path, file_path, "gamma-figsum.png")
            omega = os.path.join(folder_path, file_path, "omega.dat")

            file_path = os.path.join(folder_path, file_path, "CONTCAR")

            print(file_path, current_count)
            # ç”ŸæˆåŒ…å« entry_id çš„ç»“æœ
            if parse_poscar_composition(file_path, current_count) != "error":
                result = parse_poscar_composition(file_path, current_count)
                print(f"Inserting document with entry_id: {result['entry_id']}")
                # å”¯ä¸€åˆ¤æ–­è¡¨ç¤º
                lattice = result["structure"]["lattice"]
                sites = result["structure"]["sites"]

                # å‡†å¤‡è¦æ›¿æ¢çš„æ•°æ®ï¼Œæ³¨æ„ï¼šä¸èƒ½åŒ…å«_idå­—æ®µï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                data_to_replace = result.copy()
                if '_id' in data_to_replace:
                    del data_to_replace['_id']  # ç§»é™¤_idå­—æ®µï¼Œå› ä¸ºMongoDBä¸å…è®¸æ›¿æ¢_id

                query = {"structure.lattice": lattice
                    , "structure.sites": sites}
                existing_doc = collection.find_one(query)

                if existing_doc:
                    print(existing_doc)
                print("*****" * 10)

                if existing_doc:
                    # ä¿ç•™åŸæœ‰çš„entry_id
                    data_to_replace['entry_id'] = existing_doc['entry_id']

                # ä½¿ç”¨replace_oneå¹¶è®¾ç½®upsert=True
                replace_result = collection.replace_one(
                    query,
                    data_to_replace,
                    upsert=True
                )

                entry_id = data_to_replace['entry_id']

                if replace_result.upserted_id is not None:
                    print(f"{current_count} æ–°æ–‡æ¡£å·²æ’å…¥: {file_path} (ID: {entry_id})")
                    current_count += 1
                else:
                    print(f"{current_count} ç»“æ„å·²å­˜åœ¨!!!!!!!!!!!!!!!!!!ï¼Œå·²å¼ºåˆ¶æ›¿æ¢æ–‡æ¡£: {file_path} (ID: {entry_id})")
                    print("!!!!!!!!!!" * 20)

                base_dir = os.path.dirname(file_path)  # è·å–æ–‡ä»¶æ‰€åœ¨ç›®å½•
                target_dir = os.path.join(base_dir, entry_id)  # ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
                os.makedirs(target_dir, exist_ok=True)  # åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰

                target_file = os.path.join(target_dir, f"{formula}.vasp")

                # ç§»åŠ¨æ–‡ä»¶
                try:
                    shutil.copy2(file_path, target_file)
                except FileNotFoundError:
                    print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
                except Exception as e:
                    print(f"å¤åˆ¶æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {file_path} -> {str(e)}")

                try:
                    shutil.copy2(gamma_png, target_dir)
                except FileNotFoundError:
                    print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {gamma_png}")
                except Exception as e:
                    print(f"å¤åˆ¶æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {gamma_png} -> {str(e)}")

                try:
                    shutil.copy2(omega, target_dir)
                except FileNotFoundError:
                    print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {omega}")
                except Exception as e:
                    print(f"å¤åˆ¶æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {omega} -> {str(e)}")
